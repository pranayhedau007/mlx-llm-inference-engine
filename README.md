# mlx-llm-inference-engine
Optimised LLM inference engine for Apple Silicon(M-series) using MLX. Implements KV cache, efficient decoding and performance benchmarking.
